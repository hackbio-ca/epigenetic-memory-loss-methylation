#!/usr/bin/env python3
"""
Test script to verify CSV to H5 conversion and prediction pipeline
"""

import pandas as pd
import numpy as np
import joblib
import h5py
import os
import sys

def test_csv_conversion():
    """Test the CSV to H5 conversion process"""
    print("ğŸ§¬ Testing CSV to H5 Conversion Process")
    print("=" * 50)
    
    # Check if required files exist
    required_files = [
        "out.csv",
        "Temp.pkl", 
        "Disease_SHAP_Values.txt"
    ]
    
    for file in required_files:
        if os.path.exists(file):
            print(f"âœ… {file} exists")
        else:
            print(f"âŒ {file} missing")
            return False
    
    # Load SHAP values and get top features
    print("\nğŸ“Š Loading SHAP values...")
    try:
        total_mean_SHAP_values = np.loadtxt("Disease_SHAP_Values.txt")
        topNFeatures = np.argsort(total_mean_SHAP_values)[-500:][::-1].tolist()
        featureIndices = np.array(sorted(topNFeatures))
        print(f"âœ… Loaded {len(featureIndices)} top features")
    except Exception as e:
        print(f"âŒ Error loading SHAP values: {e}")
        return False
    
    # Load and process CSV
    print("\nğŸ“ Loading out.csv...")
    try:
        df = pd.read_csv("out.csv", index_col=0)
        print(f"âœ… CSV loaded: {df.shape[0]} CpG sites, {df.shape[1]} samples")
        print(f"   First few CpG sites: {df.index[:5].tolist()}")
    except Exception as e:
        print(f"âŒ Error loading CSV: {e}")
        return False
    
    # Convert to numpy array
    print("\nğŸ”„ Converting to numpy array...")
    try:
        data_array = df.T.values  # shape will be (1, n_features)
        print(f"âœ… Converted to array: {data_array.shape}")
    except Exception as e:
        print(f"âŒ Error converting to array: {e}")
        return False
    
    # Apply feature selection
    print("\nğŸ¯ Applying feature selection...")
    try:
        if data_array.shape[1] >= len(featureIndices):
            data = data_array[0, featureIndices]
            data = data.reshape(1, -1)
            print(f"âœ… Feature selection applied: {data.shape}")
        else:
            print(f"âš ï¸  Not enough features. Available: {data_array.shape[1]}, Required: {len(featureIndices)}")
            # Use available features
            available_indices = featureIndices[featureIndices < data_array.shape[1]]
            data = data_array[0, available_indices]
            # Pad with zeros
            padding = np.zeros((1, len(featureIndices) - len(available_indices)))
            data = np.concatenate([data, padding], axis=1)
            print(f"âœ… Feature selection with padding: {data.shape}")
    except Exception as e:
        print(f"âŒ Error in feature selection: {e}")
        return False
    
    # Test model loading and prediction
    print("\nğŸ¤– Testing model prediction...")
    try:
        model = joblib.load("Temp.pkl")
        print(f"âœ… Model loaded successfully")
        
        # Make prediction
        prediction = model.predict(data)
        print(f"âœ… Prediction made: {prediction}")
        
        # Get prediction probabilities if available
        if hasattr(model, 'predict_proba'):
            probabilities = model.predict_proba(data)
            print(f"âœ… Probabilities: {probabilities}")
        
    except Exception as e:
        print(f"âŒ Error in model prediction: {e}")
        return False
    
    print("\nğŸ‰ All tests passed! CSV to H5 conversion pipeline is working.")
    return True

def test_data_service_integration():
    """Test the data service integration"""
    print("\nğŸ”§ Testing Data Service Integration")
    print("=" * 50)
    
    try:
        # Import the data service
        sys.path.append('backend')
        from services.data_service import DataService
        
        # Create data service instance
        data_service = DataService()
        print("âœ… Data service created")
        
        # Test with a mock file upload
        from fastapi import UploadFile
        from io import BytesIO
        
        # Read out.csv and create a mock upload file
        with open("out.csv", "rb") as f:
            content = f.read()
        
        # Create mock upload file
        mock_file = UploadFile(
            filename="out.csv",
            file=BytesIO(content)
        )
        
        print("âœ… Mock upload file created")
        
        # This would need to be run in an async context
        print("â„¹ï¸  Data service integration test requires async context")
        print("   Run the backend server to test full integration")
        
    except Exception as e:
        print(f"âŒ Error testing data service: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("ğŸ§¬ Epigenetic Memory Loss Methylation - Conversion Test")
    print("=" * 60)
    
    # Test basic conversion
    conversion_success = test_csv_conversion()
    
    # Test data service integration
    integration_success = test_data_service_integration()
    
    print("\n" + "=" * 60)
    if conversion_success and integration_success:
        print("ğŸ¯ ALL TESTS PASSED - System is ready!")
    else:
        print("âš ï¸  Some tests failed - Check the output above")
    print("=" * 60)
